#!/usr/bin/python

import logging
import json
import os
#import uuid
import base64
import pathlib

# --------------------------------------------------------------------------------------
# Save this code in file "process_wrapper.py" and adapt as indicated in inline comments.
#
# Notes:
#  - This is a Python 3 script.
#  - The inputs will be given values by name, thus their order has no importance ...
#  - ... except that the inputs with a default value must be listed last.
#  - Parameter names are automatically converted into valid Python variable names.
#  - Any empty line or line starting with a '#' character will be ignored.
# --------------------------------------------------------------------------------------

logger = logging.getLogger(__name__)
logging.basicConfig(level=logging.INFO)

def execute(out_dir, layer_id, field_geojson, daterange_json):
    """
    Inputs:
    layer_id -- layer_id -- 45/User String
    field_geojson -- field_geojson -- 45/User String
    daterange_json -- daterange_json -- 45/User String

    Outputs:
    status_json -- status_json -- 45/User String
    phenology_json -- phenology_json -- 45/User String

    Main Dependency:
    mep-wps/uc-bundle-1

    Software Dependencies:
    pywps-4

    Processing Resources:
    ram -- 1
    disk -- 1
    cpu -- 1
    gpu -- 0
    """

    # ----------------------------------------------------------------------------------
    # Insert your own code below.
    # The files generated by your code must be stored in the "out_dir" folder.
    # Only the content of that folder is persisted in the datastore.
    # Give appropriate values to the output parameters. These will be passed to the next
    # process(es) following the workflow connections.
    # ----------------------------------------------------------------------------------

    logger.info("Starting...")

    status_json = ["definition"]
    phenology_json = ""

#    openeo_url = 'http://openeo-dev.vgt.vito.be/openeo/1.0.0/'
    openeo_url = 'http://openeo.vgt.vito.be/openeo/1.0.0/'
    openeo_user=os.environ.get('USER', 'anonymous')
    openeo_pass=openeo_user+'123'
    #logfile="/data/public/"+openeo_user+"/garbage/"+str(uuid.uuid4().hex)+".log"

    def log_everywhere(msg:str):
        #print(msg)
        logger.info(msg)
        status_json.append(msg)
        #with open(logfile,"a+") as f: f.write(msg+"\n")

    def timeseries_query():

        log_everywhere("TIME SERIES enter "+field_geojson)

        # find the extents, utm zone in epsg code for lat/lon of centroid and the bounding box polygon
        fields=json.loads(field_geojson)
        polys = shapely.geometry.GeometryCollection([shapely.geometry.shape(feature["geometry"]).buffer(0) for feature in fields["features"]])
        polys = affinity.scale(polys, 1., 1.)
        extent = dict(zip(["west", "south", "east", "north"], polys.bounds))
        extent['crs'] = "EPSG:4326"
        bboxpoly=shapely.geometry.Polygon.from_bounds(*polys.bounds)
    
        log_everywhere("geomlookup")

        # connection
        eoconn = openeo.connect(openeo_url)
        eoconn.authenticate_basic(openeo_user, openeo_pass)

        log_everywhere("authenticated")
    
        # prepare the Sentinel-2 bands via masking by the scene classification layer 
        daterange=json.loads(daterange_json)
        result = (
            eoconn\
                .load_collection(layer_id)\
                .filter_temporal(daterange['start'],daterange['end'])\
                .filter_bbox(**extent)\
                .polygonal_mean_timeseries(polys)\
                .execute()
        )
    
        log_everywhere("queried")
    
        for ipoly in range(len(fields["features"])):
            ts= sorted(
                    list(
                        filter(
                            lambda g: g[1] is not None,
                            map(
                                lambda i: (i[0],i[1][ipoly][0]),
                                filter(
                                    lambda f: len(f[1][ipoly])>0,
                                    result.items()
                                )
                            )
                        )
                    ),
                    key=lambda k: k[0]
                )
            fields["features"][ipoly]["timeseries"]=ts
            del fields["features"][ipoly]["geometry"]        

        log_everywhere("TIME SERIES exit "+json.dumps(fields))
        return fields


    class PhenologypParams:
        def __init__(self,):
            self.sStart=pandas.DateOffset(months=4, days=2)  # Start date of interval for start of season
            self.sEnd=  pandas.DateOffset(months=6, days=10) # End date of tart interval for start of season
            self.mStart=pandas.DateOffset(months=6, days=10) # Start date of interval for mid of season
            self.mEnd=  pandas.DateOffset(months=9, days=1) # End date of tart interval for mid of season
            self.eStart=pandas.DateOffset(months=9, days=1) # Start date of interval for end of season
            self.eEnd=  pandas.DateOffset(months=12,days=31) # End date of tart interval for end of season
            self.tSos=  10.          # Threshold for start of season
            self.tEos=  10.          # Threshold for end of season


    class CropPhenology:
    
        def __init__(self):
            self.params = ['sos', 'eos']
    
        def smooth(self, timeseries, method=['Rolling Mean', 'SWETS'], window_size=10):
            smoothed = timeseries.copy()
            if method == 'Rolling Mean': smoothed.Greenness = timeseries.Greenness.rolling(window_size, center=True).mean()
            return smoothed
    
        def extractSeasonDates(self, timeseries, args):
            result = {'sos': {'time': '', 'greenness': ''}, 'eos': {'time': '', 'greenness': ''}}
            if timeseries is None:
                return None
            else:
                year=2019
                #timeseries = self.ts.smooth(timeseries, method='Rolling Mean')
                timeseries = self.smooth(timeseries, method='Rolling Mean')
                timeseries.dropna(inplace=True)
                # Get the local maximum greenness
                mMax = self.getLocalMax(timeseries, pandas.Timestamp(year,args.mStart.months,args.mStart.days), pandas.Timestamp(year,args.mEnd.months,args.mEnd.days))
                dmMax = mMax['Times']
                ymMax = mMax['Greenness']
                # Get the start of season dates
                sos = self.getStartOfSeason(timeseries, pandas.Timestamp(year,args.sStart.months,args.sStart.days), pandas.Timestamp(year,args.sEnd.months,args.sEnd.days), float(args.tSos), float(ymMax))
                result['sos']['time'] = sos[3].strftime('%Y-%m-%d')
                result['sos']['greenness'] = sos[2]
                # Get the end of season dates
                eos = self.getEndOfSeason(timeseries, pandas.Timestamp(year,args.eStart.months,args.eStart.days), pandas.Timestamp(year,args.eEnd.months,args.eEnd.days), float(args.tEos), float(ymMax))
                result['eos']['time'] = eos[3].strftime('%Y-%m-%d')
                result['eos']['greenness'] = eos[2]
    
                return result
    
        def getLocalMax(self, df, start, end):
            df_range = df.loc[df['Times'].between(start, end)]
            return df_range.loc[df_range['Greenness'].idxmax()]
    
        def getStartOfSeason(self, df, start, end, offset, yMax):
            # Get the local minimum greenness in the start season interval
            df_sRange = df.loc[df['Times'].between(start, end)]
            sMin = df_sRange.loc[df_sRange['Greenness'].idxmin()]
            dsMin = sMin['Times']
            ysMin = sMin['Greenness']
            # Calculate the greenness value corresponding to the start of the season
            ySos = ysMin + ((yMax - ysMin) * (offset / 100.0))
            # Get the closest value to this greenness
            df_sRange = df_sRange.loc[df_sRange['Times'] >= dsMin]
            sos = df_sRange.iloc[(df_sRange['Greenness'] - ySos).abs().argsort()[:1]]
            return (dsMin, ysMin, ySos, pandas.to_datetime(str(sos['Times'].values[0])))
    
        def getEndOfSeason(self, df, start, end, offset, yMax):
            # Get the local minimum greenness in the start season interval
            df_eRange = df.loc[df['Times'].between(start, end)]
            eMin = df_eRange.loc[df_eRange['Greenness'].idxmin()]
            deMin = eMin['Times']
            yeMin = eMin['Greenness']
            # Calculate the greenness value corresponding to the start of the season
            yEos = yeMin + ((yMax - yeMin) * (offset / 100.0))
            # Get the closest value to this greenness
            df_eRange = df_eRange.loc[df_eRange['Times'] <= deMin]
            eos = df_eRange.iloc[(df_eRange['Greenness'] - yEos).abs().argsort()[:1]]
            return (deMin, yeMin, yEos, pandas.to_datetime(str(eos['Times'].values[0])))


    try:

        log_everywhere("started")

        import shapely.geometry
        from shapely import affinity
        import openeo
        import pandas

        log_everywhere("imported")

        #log_everywhere("custom:environ")
        #for k,v in os.environ.items(): log_everywhere("->"+k+"="+str(base64.b64encode(str(v).encode('ascii')),'ascii'))
        log_everywhere("custom:before:HOME:"+str(os.environ.get('HOME', '<HOME_NOT_FOUND>')))
        log_everywhere("custom:before:home():"+str(pathlib.Path("").home()))
        log_everywhere("custom:before:expanduser():"+str(pathlib.Path("").expanduser()))
        os.environ["HOME"]="/home/asb"
        log_everywhere("custom:after:HOME:"+str(os.environ.get('HOME', '<HOME_NOT_FOUND>')))
        log_everywhere("custom:after:home():"+str(pathlib.Path("").home()))
        log_everywhere("custom:after:expanduser():"+str(pathlib.Path("").expanduser()))
            

        ts=timeseries_query()

        log_everywhere("PHENOLOGY enter "+json.dumps(ts))
        
        params=PhenologypParams()
        for iserie in ts['features']:
            timeseries=pandas.DataFrame(
                data={
                    #list(map(lambda x: parse(x['date'], "%Y-%m-%d"), iserie["timeseries"])),
                    'Times':     [pandas.Timestamp(i[0]).tz_convert(None) for i in iserie["timeseries"]],  
                    'Greenness': [                                  i[1]  for i in iserie["timeseries"]] # json loads already converted to float
                }
            )
            cp=CropPhenology()
            iserie['phenology']=cp.extractSeasonDates(timeseries, params)
            del iserie['timeseries']
        phenology_json=json.dumps(ts)

        log_everywhere("PHENOLOGY exit "+phenology_json)
        
    except Exception as e:
        try:
            log_everywhere(str(base64.b64encode(str(e).encode('ascii')),'ascii'))
        except Exception as f:
            status_json.append(str(base64.b64encode((str(f)+" *** during *** "+str(e)).encode('ascii')),'ascii'))

    # ----------------------------------------------------------------------------------
    # The wrapper must return a dictionary that contains the output parameter values.
    # ----------------------------------------------------------------------------------
    return {
        "status_json": json.dumps(status_json),
        "phenology_json": phenology_json
    }
    
    